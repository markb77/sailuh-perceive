{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The purpose of this notebook is to build a field parser and extract the content of various fields in the CAPEC v2.11 XML file so that the field content can be directly analyzed and stored into database. The raw XML file can be downloaded at http://capec.mitre.org/data/archive/capec_v2.11.zip.  Guided by CAPEC Introduction notebook, this notebook will focus on the detail structure under attack patterns table and how parser functions work in order to extract various formats of field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = lxml.etree.parse('capec_v2.11.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Remove namespaces from XML.  \n",
    "for elem in root.getiterator(): \n",
    "    if not hasattr(elem.tag, 'find'): continue  # (1)\n",
    "    i = elem.tag.find('}') # Counts the number of characters up to the '}' at the end of the XML namespace within the XML tag\n",
    "    if i >= 0: \n",
    "        elem.tag = elem.tag[i+1:] # Starts the tag a character after the '}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and Field Parser\n",
    "\n",
    "Although the fields have been categorized based on the format in CAPEC Introduction Notebook, the Introduction Notebook is more focus on how field information is shown in the website, not in the XML raw file, thus making it useless when designing parser. \n",
    "\n",
    "The following table represents how fields are grouped when designing the parser function, from the perspective of whether there are field content stored as XML element attribute and whether the field contents can be concatenated and written as one row. Since it is difficult to name these three groups, we simply use A, B, and C to represent. In the table, all fields in the CAPEC Field Example can be parsed through the parser functions in this notebook, except Technical_Context and Target_Attack_Surface.\n",
    "\n",
    "|Format|Number of Levels|Whether content can be concatenated | Whether has information as attribute|CAPEC Field Example|Avaiable Parser Function|\n",
    "|:----:|:----:|:----:|:---------:|:---------:|:---------:|\n",
    "|A|1-4|Yes|No|Typical_Severity, Typical_Likelihood_of_Exploit, Methods_of_Attack, Resources_Required, Purposes, CIA_Impact, Payload, Activation_Zone, Summary, Attack_Prerequisites, Relevant_Security_Requirements, Related_Security_Principles, Related_Guidelines, Solutions_and_Mitigations,Probing_Techniques, Indicators-Warnings_of_Attack, Payload_Activation_Impact, Technical_Context\\*|field_parser_with_concatenation|\n",
    "|B|3-5|No|No|Attacker_Skills_or_Knowledge_Required, Attack_Motivation-Consequences, Examples-Instances|field_parser_without_concatenation|\n",
    "|C|3-4|No|Yes|References, Content_History, Related_Weakness, Related_Attack_Pattern, Target_Attack_Surface\\*|field_parser_without_concatenation|\n",
    "\n",
    "We will discuss the field structure and the table details below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1.1 Format A </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 The number of levels\n",
    "\n",
    "All fields in Format A can be generalized to the similar structure. The difference is the number of levels, which means the depth of the parsed content. Here is the generalized structure for fields that have 4 levels. For example, Probing_Techniques is the field that has 4 levels in Format A. The content we are trying to parse is under Entry_Element_Child, so that we have to parse the XML element four times in order to get Entry_Element_Child element. On the other hand, Typical_Severity is the field that only has one level, making the content directly under the Target_Field element. \n",
    "\n",
    "The idea is the same for the fields that have 2 and 3 levels. Specifically, the 2-levels fields will have Target_Field and Field_Entry, while the content will under Field_Entry element. The 3-levels fields will have Target_Field, Field_Entry, and Entry_Element, while the content will under Entry_Element element.\n",
    "\n",
    "- <b>Genarlized Structure for 4-levels fields</b>:\n",
    "    ```\n",
    "    <Target_Field>\n",
    "        <Field_Entry1>\n",
    "            <Entry_Element>\n",
    "                <Entry_Element_Child>the content function will parse</Entry_Element_Child>\n",
    "            </Entry_Element>\n",
    "        </Field_Entry1>\n",
    "        <Field_Entry2>\n",
    "            <Entry_Element> \n",
    "                <Entry_Element_Child>the content function will parse</Entry_Element_Child>\n",
    "            </Entry_Element>\n",
    "        </Field_Entry2>\n",
    "        ...\n",
    "    </Target_Field>\n",
    "```\n",
    "- <b>Example for 4-levels fields</b>:\n",
    "```\n",
    "<capec:Probing_Techniques>\n",
    "     <capec:Probing_Technique>\n",
    "         <capec:Description>\n",
    "             <capec:Text>While interacting with a system an attacker would typically investigate for environment variables that can be overwritten. The more a user knows about a system the more likely she will find a vulnerable environment variable.</capec:Text>\n",
    "         </capec:Description>\n",
    "     </capec:Probing_Technique>\n",
    "     <capec:Probing_Technique>\n",
    "         <capec:Description>\n",
    "             <capec:Text>On a web environment, the attacker can read the client side code and search for environment variables that can be overwritten.</capec:Text>\n",
    "         </capec:Description>\n",
    "     </capec:Probing_Technique>\n",
    "</capec:Probing_Techniques>\n",
    "```\n",
    "- <b>Example for 1-level field</b>\n",
    "```\n",
    "<capec:Typical_Severity>High</capec:Typical_Severity>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Concatenated content:\n",
    "\n",
    "After explaining the number of levels, here we will discuss the difference between Format A and B, and why the content will be concatenated for fields in Format A. In the example for 4-levels fields shown above, the sentence starting with 'While interacting with a system' and the sentence starting with 'On a web environment' are stored separately under two different Probing_Technique elements, but they come from the same paragraph under Probing Techniques section [(capec_10)](http://capec.mitre.org/data/definitions/10.html). Therefore, it makes sense to concatenate two sentences and output as a whole. \n",
    "\n",
    "In summary, when parsing the fields in Format A through the parser function, the content under different Field_Entry elements, no matter the number of levels, will be concatenated and written as one output. In addition, since the content will be merged, capec_id will be unique in the output CSV file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Parser Function for Format A fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before introducing the parser function, we need a function that can write the dictionary that stores the field content to a CSV file. Function <b> write_dict_to_csv </b> will append the given dictionary to the end of CSV file. If the file does not exist, the function will create a CSV file and take the csv_header as the header of this CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_dict_to_csv(output_file,csv_header,dict_data):\n",
    "    '''\n",
    "    Create a CSV file with headers and write a dictionary;\n",
    "    If the file already existes, only append a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        output_file -- name of the output csv file\n",
    "        csv_header -- the header of the output csv file. \n",
    "        dict_data -- the dictionary that will be writen into the CSV file. The number of \n",
    "                     element in the dictionary should be equal to or lower than the number of\n",
    "                     headers of the CSV file. \n",
    "    \n",
    "    Outcome:\n",
    "        a new csv file with headers and one row that includes the information from the dictionary;\n",
    "        or an existing CSV file with a new row that includes the information from the dictionary\n",
    "    '''\n",
    "    # create a file if the file does not exist; if exsits, open the file\n",
    "    with open(output_file, 'a',encoding='UTF-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=csv_header,lineterminator='\\n')\n",
    "        \n",
    "        # check whether the csv file is empty\n",
    "        if csv_file.tell()==0:\n",
    "            # if empty, write header and the dictionary\n",
    "            writer.writeheader()         \n",
    "            writer.writerow(dict_data)\n",
    "        else:\n",
    "            # if not empty, only write the dictionary\n",
    "            writer.writerow(dict_data)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the target field, function <b> field_parser_with_concatenation</b> will extract the content within the target field element and write capec_id and content into a CSV file named by the target field. Each row in the output CSV file will contain the following information:\n",
    "\n",
    "- capec_id: The CAPEC identifier. Since the content will be concatenated, capec_id will be a unique identifier in the output file.\n",
    "- field: The name of the target field\n",
    "- field content: The text information stored under the target field. The header name will vary depending on the field the function is parsing.\n",
    "\n",
    "There are two parts within function <b> field_parser_with_concatenation</b>. The first part will generate all possible tags as the headers of the output CSV file by traversing all child element tags under each field entry. It is very important for the first part, because once the function writes the headers, it is computationally expensive to edit the first row later. The second part will extract the content from the nesting target field and then write to a CSV file by using function <b> write_dict_to_csv </b>.\n",
    "\n",
    "The following fields have been tested successfully: Typical_Severity, Typical_Likelihood_of_Exploit, Methods_of_Attack, Resources_Required, Purposes, CIA_Impact, Payload, Activation_Zone, Summary, Attack_Prerequisites, Relevant_Security_Requirements, Related_Security_Principles, Related_Guidelines, Solutions_and_Mitigations,Probing_Techniques, Indicators-Warnings_of_Attack, Payload_Activation_Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def field_parser_with_concatenation(target_field, root):\n",
    "    '''\n",
    "    Parse the field from capec_v2.11.xml file and output the information to a csv file.\n",
    "    \n",
    "    Args:\n",
    "        target_field -- the target field that will be parsed through this function. The format of this arg should be string.\n",
    "        root -- the root element of the whole parsed tree. \n",
    "    Outcome:\n",
    "        a csv file named by the field name. Each row will include the following information:\n",
    "            - capec_id: The CAPEC identifier\n",
    "            - field: The name of the target field\n",
    "            - file content: The text information stored under the target field.\n",
    "    '''\n",
    "    \n",
    "    # define the path of target field. Here we select all element nodes that the tag is the target field\n",
    "    # if the target field is Summary field, please use the following path: \n",
    "    #target_field_path='Attack_Pattern/Description/'+target_field\n",
    "    target_field_path='Attack_Pattern/./'+target_field\n",
    "   \n",
    "    # extract attack pattern table in the XML\n",
    "    attack_pattern_table = root[2]\n",
    "    # define the headers\n",
    "    output_header=['capec_id','field']\n",
    "    # define path of the output file\n",
    "    output_path=target_field+'.csv'\n",
    "    \n",
    "    ### 1.Generate all possible tags(column header in csv file) under the target field tree\n",
    "    # for each target field node\n",
    "    for field in attack_pattern_table.findall(target_field_path):\n",
    "        # check whether there is no content under target field; if yes, then go to next capec-id:\n",
    "        if  type(field.text)==type(None):\n",
    "            continue\n",
    "        # extract the content under field element\n",
    "        field_content=field.text\n",
    "        \n",
    "        # if there is field_entry element under target_field  // will move to level 2\n",
    "        if field_content.isspace():\n",
    "            # for each field entry node under the target field node\n",
    "            for field_entry in list(field):\n",
    "                # extract the tag and content information for field entry\n",
    "                field_entry_tag=field_entry.tag\n",
    "                field_entry_content=field_entry.text\n",
    "\n",
    "                # in case there is an empty element without any content\n",
    "                if type(field_entry_content)==type(None):\n",
    "                    continue\n",
    "                    \n",
    "                # if there is no child element under field_entry // stop to level 2\n",
    "                elif not field_entry_content.isspace():\n",
    "                    # if the tag is 'Text', we will replace the tag by its field naming\n",
    "                    if field_entry_tag.lower()=='text':\n",
    "                        field_entry_tag=target_field\n",
    "\n",
    "                    # append the tag to the output_header list if it does not exist in the list\n",
    "                    if field_entry_tag.lower() not in output_header:\n",
    "                        output_header.append(field_entry_tag.lower())\n",
    "                        \n",
    "                # if there is element under field_entry // will move to level 3\n",
    "                elif field_entry_content.isspace():\n",
    "\n",
    "                    # traverse all entry_element nodes under each field entry\n",
    "                    for entry_element in list(field_entry):\n",
    "                        # generate tag and content of each entry_element\n",
    "                        entry_element_tag=entry_element.tag\n",
    "                        entry_element_content=entry_element.text\n",
    "                        # build the distinguishable tag for content for furture usage\n",
    "                        field_element_header=field_entry_tag+'_'+entry_element_tag\n",
    "                        # append the tag to the output_header list if it does not exist in the list\n",
    "                        if field_element_header.lower() not in output_header:\n",
    "                            output_header.append(field_element_header.lower())\n",
    "                        # if there is not content, then move to next entry element\n",
    "                        if type(entry_element_content)==type(None):\n",
    "                                continue\n",
    "        ### stop to level 1\n",
    "        # if there is no field_entry element under target_field           \n",
    "        else:\n",
    "            if target_field.lower() not in output_header:\n",
    "                output_header.append(target_field.lower())\n",
    "                \n",
    "    ### 2.Extract the content from the nesting target field\n",
    "    # for each target field node\n",
    "    for field in attack_pattern_table.findall(target_field_path):\n",
    "        # check whether there is no content under target field; if yes, then go to next capec-id:\n",
    "        if  type(field.text)==type(None):\n",
    "            continue\n",
    "            \n",
    "        # extract capec_id from the attribute of its parent node\n",
    "        # if the target field is Summary field, please use the following code to extract capec_id: \n",
    "        #capec_id=field.getparent().getparent().attrib.get('ID')\n",
    "        capec_id=field.getparent().attrib.get('ID')\n",
    "        \n",
    "        # the dictionary that will be written to a CSV file\n",
    "        field_dict=dict()\n",
    "        field_dict['capec_id']=capec_id\n",
    "        field_dict['field']=target_field\n",
    "        field_content=field.text\n",
    "        \n",
    "        # if there is field_entry element under target_field // will move to level 2\n",
    "        if field_content.isspace():\n",
    "            # for each field entry node under the target field node\n",
    "            for field_entry in list(field):\n",
    "                # extract the tag and content information for field entry\n",
    "                field_entry_tag=field_entry.tag\n",
    "                field_entry_content=field_entry.text\n",
    "\n",
    "                # in case there is an empty element without any content\n",
    "                if type(field_entry_content)==type(None):\n",
    "                    continue\n",
    "\n",
    "                # if there is no node under field_entry // will stop to level 2\n",
    "                elif not field_entry_content.isspace():\n",
    "                    if field_entry_tag.lower()=='text':\n",
    "                        field_entry_tag=target_field\n",
    "\n",
    "                    #if there are multiple field entries using a same tag, all content will be concatenated\n",
    "                    if field_entry_tag.lower() in field_dict:\n",
    "                        # add the concatenated content into the dictionary \n",
    "                        field_dict[field_entry_tag.lower()]=field_dict[field_entry_tag.lower()]+ ';'+field_entry_content.strip()\n",
    "\n",
    "                    # if not, directly add the field_entry content into the dictionary\n",
    "                    else:\n",
    "                        field_dict[field_entry_tag.lower()]=field_entry_content.strip()\n",
    "\n",
    "                # if there is element under field_entry // will move to level 3\n",
    "                elif field_entry_content.isspace():\n",
    "\n",
    "                    # traverse all entry_element nodes under each field entry\n",
    "                    for entry_element in list(field_entry):\n",
    "                        # generate tag and content of each entry_element\n",
    "                        entry_element_tag=entry_element.tag\n",
    "                        entry_element_content=entry_element.text\n",
    "                        # build the distinguishable tag for content for furture usage\n",
    "                        field_element_header=field_entry_tag+'_'+entry_element_tag\n",
    "\n",
    "                        # if there is not content, then move to next entry element\n",
    "                        if type(entry_element_content)==type(None):\n",
    "                                continue\n",
    "\n",
    "                        # if there is no element under entry_element // will stop level 3\n",
    "                        if not entry_element_content.isspace():\n",
    "                            # concatenate all entry element content\n",
    "                            field_content=field_content.strip()+' '+entry_element_content.strip()\n",
    "                        # if there is element under entry_element // will move to level 4\n",
    "                        else:\n",
    "                            # traverse all elements under entry_element\n",
    "                            for entry_element_child in list(entry_element):\n",
    "                                # extract the content for each element under entry_element\n",
    "                                entry_element_child_content=entry_element_child.text\n",
    "                                # concatenate all element content under each entry_element\n",
    "                                field_content=field_content.strip()+' '+entry_element_child_content.strip()\n",
    "                    # add the tag and content pairs to the output dictionary\n",
    "                    field_dict[field_element_header.lower()]=field_content.strip()\n",
    "                    \n",
    "        # if there is no field_entry element under target_field // will stop to level 1\n",
    "        else:\n",
    "            field_dict[target_field.lower()]=field_content.strip()\n",
    "        # write the dictionary with headers to a CSV file \n",
    "        write_dict_to_csv(output_path,output_header,field_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### the target field that can be parsed by this function\n",
    "## 1 level\n",
    "severity='Typical_Severity'\n",
    "\n",
    "## 2 levels:\n",
    "method_attack='Methods_of_Attack' \n",
    "resource='Resources_Required'  \n",
    "purpose='Purposes' \n",
    "impact='CIA_Impact' \n",
    "payload='Payload' \n",
    "likelihood_exploit='Typical_Likelihood_of_Exploit'\n",
    "activation_zone='Activation_Zone' \n",
    "# Since the Summary field is under Description field,\n",
    "# please change the target_field path and the way to get capec_id \n",
    "summary='Summary' \n",
    "\n",
    "## 3 levels\n",
    "prerequisite='Attack_Prerequisites'   \n",
    "security_requirement='Relevant_Security_Requirements'\n",
    "security_principle='Related_Security_Principles'\n",
    "guideline='Related_Guidelines' \n",
    "mitigation='Solutions_and_Mitigations'\n",
    "\n",
    "## 4 levels:\n",
    "probing='Probing_Techniques' \n",
    "indicator='Indicators-Warnings_of_Attack'\n",
    "payload_impact='Payload_Activation_Impact' \n",
    "\n",
    "# parse the target field\n",
    "field_parser_with_concatenation(probing,root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capec_id</th>\n",
       "      <th>field</th>\n",
       "      <th>probing_technique_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Probing_Techniques</td>\n",
       "      <td>In the case of web applications, use of a spid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Probing_Techniques</td>\n",
       "      <td>While interacting with a system an attacker wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Probing_Techniques</td>\n",
       "      <td>The adversary sends an overly long input in va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>Probing_Techniques</td>\n",
       "      <td>The attacker can probe for enabled SSI by inje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>Probing_Techniques</td>\n",
       "      <td>Use available tools to snoop on communications...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   capec_id               field  \\\n",
       "0         1  Probing_Techniques   \n",
       "1        10  Probing_Techniques   \n",
       "2       100  Probing_Techniques   \n",
       "3       101  Probing_Techniques   \n",
       "4       102  Probing_Techniques   \n",
       "\n",
       "                       probing_technique_description  \n",
       "0  In the case of web applications, use of a spid...  \n",
       "1  While interacting with a system an attacker wo...  \n",
       "2  The adversary sends an overly long input in va...  \n",
       "3  The attacker can probe for enabled SSI by inje...  \n",
       "4  Use available tools to snoop on communications...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output CSV file\n",
    "field_with_concatenation=pd.read_csv('Probing_Techniques.csv')\n",
    "field_with_concatenation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Format B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the fields in Format B and C have the similar nested structure as the fields in Format A, the difference is that there are multiple bottom elements storing different aspects of information, thus making content parsed meaningless to be concatenated. \n",
    "\n",
    "Here is the example for Attack_Skill_or_Knowledge_Required field under capec-10. In the example, each field_entry element has two entry_element elements that store the level and type of the skill or knowledge for capec-10. Therefore, it makes no sense to represent two different attacker skills or knowledge required in one row. From the [capec_10](http://capec.mitre.org/data/definitions/10.html), we can have the same conclusion. \n",
    "\n",
    "As a result, when parsing the following example, the parser function will separate these two skills and output two rows that have a same capec_id and different content. \n",
    "\n",
    "<b> Example for Format B </b>\n",
    "```\n",
    "<capec:Attacker_Skills_or_Knowledge_Required>\n",
    "\n",
    "   <capec:Attacker_Skill_or_Knowledge_Required>\n",
    "      <capec:Skill_or_Knowledge_Level>Low</capec:Skill_or_Knowledge_Level>\n",
    "        <capec:Skill_or_Knowledge_Type>\n",
    "           <capec:Text>An attacker can simply overflow a buffer by inserting a long string into an attacker-modifiable injection vector. The result can be a DoS.</capec:Text>\n",
    "        </capec:Skill_or_Knowledge_Type>\n",
    "       </capec:Attacker_Skill_or_Knowledge_Required>\n",
    "   <capec:Attacker_Skill_or_Knowledge_Required>\n",
    "   \n",
    "      <capec:Skill_or_Knowledge_Level>High</capec:Skill_or_Knowledge_Level>\n",
    "        <capec:Skill_or_Knowledge_Type>\n",
    "           <capec:Text>Exploiting a buffer overflow to inject malicious code into the stack of a software system or even the heap can require a higher skill level.</capec:Text>\n",
    "        </capec:Skill_or_Knowledge_Type>\n",
    "   </capec:Attacker_Skill_or_Knowledge_Required>\n",
    "   \n",
    "</capec:Attacker_Skills_or_Knowledge_Required>\n",
    "```\n",
    "\n",
    "<b> Parsing output for the above example</b>\n",
    "\n",
    "![attacker_skills](images/attacker_skills.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the target field, function <b> field_parser_without_concatenation</b> will extract the content within the target field element and write capec_id and content into a CSV file named by the target field. Each row in the output CSV file will contain the following information:\n",
    "\n",
    "- capec_id: The CAPEC identifier. Since the content will be not concatenated, capec_id will not be unique in the output file.\n",
    "- field: The name of the target field\n",
    "- field content: The text information stored under the target field. The header name will vary based on the field the function is parsing.\n",
    "\n",
    "There are two parts within function <b> field_parser_without_concatenation</b>. The first part will generate all possible tags as the headers of the output CSV file by traversing all child element tags under each field entry. It is very important for the first part, because once the function writes the headers, it is computationally expensive to edit the first row later. The second part will extract the content from the nesting target field and then write to a CSV file by using function <b> write_dict_to_csv </b>.\n",
    "\n",
    "The following fields have been tested successfully: Attacker_Skills_or_Knowledge_Required, Attack_Motivation-Consequences, Examples-Instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def field_parser_without_concatenation(target_field, root):\n",
    "    '''\n",
    "    Parse the field from capec_v2.11.xml file and output the information to a csv file.\n",
    "    \n",
    "    Args:\n",
    "        target_field -- the target field that will be parsed through this function. The format of this arg should be string.\n",
    "        root -- the root element of the whole parsed tree. \n",
    "    Outcome:\n",
    "        a csv file named by the field name. Each row will include the following information:\n",
    "            - capec_id: The CAPEC identifier\n",
    "            - field: The name of the target field\n",
    "            - file content: The text information stored under the target field.\n",
    "    '''\n",
    "        \n",
    "    # define the path of target field. Here we select all element nodes that the tag is the target field\n",
    "    target_field_path='Attack_Pattern/./'+target_field\n",
    "    # extract attack pattern table in the XML\n",
    "    attack_pattern_table = root[2]\n",
    "    # define the headers\n",
    "    output_header=['capec_id','field']\n",
    "    # define path of the output file\n",
    "    output_path=target_field+'.csv'\n",
    "    \n",
    "    ##### 1. Generate all possible tags(column header in csv file) under the target field tree\n",
    "    # for each target field node\n",
    "    for field in attack_pattern_table.findall(target_field_path):\n",
    "        \n",
    "        # check whether there is no content under target field; if yes, then go to next capec-id:\n",
    "        if  type(field.text)==type(None):\n",
    "            continue\n",
    "        capec_id=field.getparent().attrib.get('ID')\n",
    "        # for each field entry, in case there are multiple field entries under the target field node // will move to level 2\n",
    "        for field_entry in list(field):\n",
    "            # traverse all entry_element nodes under each field entry // will move to level 3\n",
    "            for entry_element in list(field_entry):\n",
    "                # generate tag and content of each entry_element\n",
    "                entry_element_tag=entry_element.tag\n",
    "                entry_element_content=entry_element.text\n",
    "                \n",
    "                # if there is one more element under entry_element // will move to level 4\n",
    "                if entry_element_content.isspace():\n",
    "                    # traverse all elements under entry_element \n",
    "                    for entry_element_child in list(entry_element):\n",
    "                        # generate tag and content of each element under entry_element\n",
    "                        entry_element_child_tag=entry_element_child.tag\n",
    "                        entry_element_child_content=entry_element_child.text\n",
    "                        \n",
    "                        # if there is one more element under entry_element_child // will move to level 5\n",
    "                        if entry_element_child_content.isspace():\n",
    "                            # traverse all elements under entry_element_child\n",
    "                            for entry_element_child_embed in list(entry_element_child):\n",
    "                                # build the distinguishable tag for content for furture usage\n",
    "                                entry_element_child_embed_tag=entry_element_child_embed.tag\n",
    "                                field_entry_header=entry_element_child_tag+'_'+entry_element_child_embed_tag\n",
    "                                # append the tag to the output_header list if it does not exist in the list\n",
    "                                if field_entry_header.lower() not in output_header:\n",
    "                                    output_header.append(field_entry_header.lower())\n",
    "                        \n",
    "                        # if there no element under entry_element_child // will stop to level 4\n",
    "                        else:\n",
    "                            # build the distinguishable tag for content for furture usage\n",
    "                            field_entry_header=entry_element_tag+'_'+entry_element_child_tag\n",
    "                            # append the tag to the output_header list if it does not exist in the list\n",
    "                            if field_entry_header.lower() not in output_header:\n",
    "                                output_header.append(field_entry_header.lower())\n",
    "                                \n",
    "                # if there is no entry_element under field_entry // will stop to level 3    \n",
    "                else:\n",
    "                    # append the tag to the output_header list if it does not exist in the list\n",
    "                    if entry_element_tag.lower() not in output_header:\n",
    "                        output_header.append(entry_element_tag.lower())\n",
    "\n",
    "    \n",
    "    #### 2. Extract the content from the target field\n",
    "    # for each target field node\n",
    "    for field in attack_pattern_table.findall(target_field_path):\n",
    "        \n",
    "         # check whether there is no content under target field; if yes, then go to next capec-id:\n",
    "        if  type(field.text)==type(None):\n",
    "            continue\n",
    "            \n",
    "        # extract capec_id from the attribute of its parent node\n",
    "        capec_id=field.getparent().attrib.get('ID')\n",
    "        \n",
    "        # for each field entry, in case there are multiple field entries under the target field node // will move to level 2\n",
    "        for field_entry in list(field):\n",
    "            \n",
    "            # the dictionary that will be written to a CSV file\n",
    "            field_entry_dict=dict()\n",
    "            field_entry_dict['capec_id']=capec_id\n",
    "            field_entry_dict['field']=target_field\n",
    "            \n",
    "            # traverse all entry_element nodes under each field entry // will move to level 3\n",
    "            for entry_element in list(field_entry):\n",
    "                \n",
    "                # generate tag and content of each entry_element\n",
    "                entry_element_tag=entry_element.tag\n",
    "                entry_element_content=entry_element.text\n",
    "                \n",
    "                # if there is one more element under entry_element // will move to level 4\n",
    "                if entry_element_content.isspace():\n",
    "                    # traverse all elements under each entry_element\n",
    "                    for entry_element_child in list(entry_element):\n",
    "                        # generate tag and content of each element under entry_element\n",
    "                        entry_element_child_tag=entry_element_child.tag\n",
    "                        entry_element_child_content=entry_element_child.text\n",
    "                        # build the distinguishable tag for content for furture usage\n",
    "                        field_entry_header=entry_element_tag+'_'+entry_element_child_tag\n",
    "                    \n",
    "                        # if there is one more element under entry_element_child // will move to level 5\n",
    "                        if entry_element_child_content.isspace():\n",
    "                            # traverse all elements under each entry_element_child\n",
    "                            for entry_element_child_embed in list(entry_element_child):\n",
    "                                # generate tag and content of each element under entry_element_child\n",
    "                                entry_element_child_embed_tag=entry_element_child_embed.tag\n",
    "                                entry_element_child_embed_content=entry_element_child_embed.text\n",
    "                                \n",
    "                                # if there is no content, then move to next element\n",
    "                                if type(entry_element_child_embed_content)==type(None):\n",
    "                                    continue\n",
    "                                    \n",
    "                                # build the distinguishable tag for content for furture usage \n",
    "                                field_entry_header=entry_element_child_tag+'_'+entry_element_child_embed_tag\n",
    "                                \n",
    "                                # if there is multiple elements that share a same tag\n",
    "                                if field_entry_header.lower() in field_entry_dict:\n",
    "                                # add the concatenated content into the dictionary \n",
    "                                    field_entry_dict[field_entry_header.lower()]=field_entry_dict[field_entry_header.lower()]+ ';'+ entry_element_child_embed_content\n",
    "                                # if not, directly add the content into the dictionary\n",
    "                                else:\n",
    "                                    field_entry_dict[field_entry_header.lower()]= entry_element_child_embed_content\n",
    "                        \n",
    "                        # if there no element under entry_element_child // will stop to level 4\n",
    "                        else:\n",
    "                            # build the distinguishable tag for content for furture usage \n",
    "                            field_entry_header=entry_element_tag+'_'+entry_element_child_tag                            \n",
    "                            # if there is multiple elements that share a same tag\n",
    "                            if field_entry_header.lower() in field_entry_dict:\n",
    "                            # add the concatenated content into the dictionary \n",
    "                                field_entry_dict[field_entry_header.lower()]=field_entry_dict[field_entry_header.lower()]+ ';'+ entry_element_child_content\n",
    "                            # if not, directly add the entry_element_child content into the dictionary\n",
    "                            else:\n",
    "                                field_entry_dict[field_entry_header.lower()]= entry_element_child_content\n",
    "                # if there is no element under entry_element // will stop to 3\n",
    "                else:\n",
    "                    # if there is multiple elements that share a same tag\n",
    "                    if entry_element_tag.lower() in field_entry_dict:\n",
    "                    # add the concatenated content into the dictionary \n",
    "                        field_entry_dict[entry_element_tag.lower()]=field_entry_dict[entry_element_tag.lower()]+ ';'+entry_element_content\n",
    "                    # if not, directly add the entry_element content into the dictionary\n",
    "                    else:\n",
    "                        field_entry_dict[entry_element_tag.lower()]=entry_element_content\n",
    "\n",
    "            # write the dictionary with headers to a CSV file    \n",
    "            write_dict_to_csv(output_path,output_header,field_entry_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the target field that can be parsed by this function\n",
    "attacker_skill='Attacker_Skills_or_Knowledge_Required' \n",
    "motivation_outcome='Attack_Motivation-Consequences'\n",
    "example='Examples-Instances'\n",
    "# parse the target field\n",
    "field_parser_without_concatenation(attacker_skill,root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capec_id</th>\n",
       "      <th>field</th>\n",
       "      <th>skill_or_knowledge_level</th>\n",
       "      <th>skill_or_knowledge_type_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Attacker_Skills_or_Knowledge_Required</td>\n",
       "      <td>Low</td>\n",
       "      <td>In order to discover unrestricted resources, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Attacker_Skills_or_Knowledge_Required</td>\n",
       "      <td>Low</td>\n",
       "      <td>An attacker can simply overflow a buffer by in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Attacker_Skills_or_Knowledge_Required</td>\n",
       "      <td>High</td>\n",
       "      <td>Exploiting a buffer overflow to inject malicio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>Attacker_Skills_or_Knowledge_Required</td>\n",
       "      <td>Low</td>\n",
       "      <td>In most cases, overflowing a buffer does not r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Attacker_Skills_or_Knowledge_Required</td>\n",
       "      <td>High</td>\n",
       "      <td>In cases of directed overflows, where the moti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   capec_id                                  field skill_or_knowledge_level  \\\n",
       "0         1  Attacker_Skills_or_Knowledge_Required                      Low   \n",
       "1        10  Attacker_Skills_or_Knowledge_Required                      Low   \n",
       "2        10  Attacker_Skills_or_Knowledge_Required                     High   \n",
       "3       100  Attacker_Skills_or_Knowledge_Required                      Low   \n",
       "4       100  Attacker_Skills_or_Knowledge_Required                     High   \n",
       "\n",
       "                        skill_or_knowledge_type_text  \n",
       "0  In order to discover unrestricted resources, t...  \n",
       "1  An attacker can simply overflow a buffer by in...  \n",
       "2  Exploiting a buffer overflow to inject malicio...  \n",
       "3  In most cases, overflowing a buffer does not r...  \n",
       "4  In cases of directed overflows, where the moti...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output CSV file\n",
    "field_without_concatenation=pd.read_csv('Attacker_Skills_or_Knowledge_Required.csv')\n",
    "field_without_concatenation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Format C\n",
    "\n",
    "The fields in Format C have the very similar structure as the fields in Format B and also face the same problem that the content cannot be concatenated. The only difference is that fields in Format C have the information stored as element attribute. \n",
    "\n",
    "Here is the example for the content history field under capec-10. The content, Submission_Source=\"Internal_CAPEC_Team\" and  Modification_Source=\"Internal\", are stored as the attribute of Submission element and Modification element, thus making the function <b>field_parser_without_concatenation </b> not applicable for the fields in Format C. However, if the content in the attribute can be ignored, the function <b>field_parser_without_concatenation </b> has the ability to parse the following fields in Format C: References, Content_History, Related_Weakness, Related_Attack_Pattern\n",
    "```\n",
    "<capec:Content_History>\n",
    "  <capec:Submissions>\n",
    "     <capec:Submission Submission_Source=\"Internal_CAPEC_Team\">\n",
    "       <capec:Submitter>CAPEC Content Team</capec:Submitter>\n",
    "          <capec:Submitter_Organization>The MITRE Corporation</capec:Submitter_Organization>\n",
    "             <capec:Submission_Date>2014-06-23</capec:Submission_Date>\n",
    "     </capec:Submission>\n",
    "  </capec:Submissions>\n",
    "  \n",
    "  <capec:Modifications>\n",
    "     <capec:Modification Modification_Source=\"Internal\">\n",
    "       <capec:Modifier>CAPEC Content Team</capec:Modifier>\n",
    "       <capec:Modifier_Organization>The MITRE Corporation</capec:Modifier_Organization>\n",
    "       <capec:Modification_Date>2017-01-09</capec:Modification_Date>\n",
    "       <capec:Modification_Comment>Updated Related_Attack_Patterns</capec:Modification_Comment>\n",
    "     </capec:Modification>\n",
    "  </capec:Modifications>\n",
    "</capec:Content_History>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the target field that can be parsed by this function, if ignoring the attribute content\n",
    "reference='References' \n",
    "content_history='Content_History'\n",
    "weakness='Related_Weaknesses'\n",
    "attack_pattern='Related_Attack_Patterns'\n",
    "# parse the target field\n",
    "field_parser_without_concatenation(content_history,root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capec_id</th>\n",
       "      <th>field</th>\n",
       "      <th>submission_submitter</th>\n",
       "      <th>submission_submitter_organization</th>\n",
       "      <th>submission_submission_date</th>\n",
       "      <th>modification_modifier</th>\n",
       "      <th>modification_modifier_organization</th>\n",
       "      <th>modification_modification_date</th>\n",
       "      <th>modification_modification_comment</th>\n",
       "      <th>previous_entry_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Content_History</td>\n",
       "      <td>CAPEC Content Team</td>\n",
       "      <td>The MITRE Corporation</td>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Content_History</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAPEC Content Team;CAPEC Content Team</td>\n",
       "      <td>The MITRE Corporation;The MITRE Corporation</td>\n",
       "      <td>2017-05-01;2017-08-04</td>\n",
       "      <td>Updated Attack_Pattern, References;Updated Att...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Content_History</td>\n",
       "      <td>CAPEC Content Team</td>\n",
       "      <td>The MITRE Corporation</td>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Content_History</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAPEC Content Team</td>\n",
       "      <td>The MITRE Corporation</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>Updated Related_Attack_Patterns</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>Content_History</td>\n",
       "      <td>CAPEC Content Team</td>\n",
       "      <td>The MITRE Corporation</td>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   capec_id            field submission_submitter  \\\n",
       "0         1  Content_History   CAPEC Content Team   \n",
       "1         1  Content_History                  NaN   \n",
       "2        10  Content_History   CAPEC Content Team   \n",
       "3        10  Content_History                  NaN   \n",
       "4       100  Content_History   CAPEC Content Team   \n",
       "\n",
       "  submission_submitter_organization submission_submission_date  \\\n",
       "0             The MITRE Corporation                 2014-06-23   \n",
       "1                               NaN                        NaN   \n",
       "2             The MITRE Corporation                 2014-06-23   \n",
       "3                               NaN                        NaN   \n",
       "4             The MITRE Corporation                 2014-06-23   \n",
       "\n",
       "                   modification_modifier  \\\n",
       "0                                    NaN   \n",
       "1  CAPEC Content Team;CAPEC Content Team   \n",
       "2                                    NaN   \n",
       "3                     CAPEC Content Team   \n",
       "4                                    NaN   \n",
       "\n",
       "            modification_modifier_organization modification_modification_date  \\\n",
       "0                                          NaN                            NaN   \n",
       "1  The MITRE Corporation;The MITRE Corporation          2017-05-01;2017-08-04   \n",
       "2                                          NaN                            NaN   \n",
       "3                        The MITRE Corporation                     2017-01-09   \n",
       "4                                          NaN                            NaN   \n",
       "\n",
       "                   modification_modification_comment previous_entry_name  \n",
       "0                                                NaN                 NaN  \n",
       "1  Updated Attack_Pattern, References;Updated Att...                 NaN  \n",
       "2                                                NaN                 NaN  \n",
       "3                    Updated Related_Attack_Patterns                 NaN  \n",
       "4                                                NaN                 NaN  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output CSV file\n",
    "field_without_concatenation=pd.read_csv('Content_History.csv')\n",
    "field_without_concatenation.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
