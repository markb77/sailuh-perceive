{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Overview\n",
    "\n",
    "**1.1 TITLE** ‒ _Introduction to social networking analysis of the Full Disclosure email network_\n",
    "\n",
    "**1.2 DESCRIPTION** ‒ A security email list includes useful information for predictive analysis of emerging threats, but this information may be lost alongside irrelevant discussion threads. Social network analysis provides one method to identify and filter out unwanted messages. This introductory notebook develops techniques to concentrate on the core content of the email network studied.\n",
    "\n",
    "**1.3 ABSTRACT** ‒ This notebook begins with preliminary analysis and exploration of the Full Disclosure email network, developing a general sense of the network's structure over time and within a single year. The general overview reveals that the email list changed in character over time, growing in activity in early year but declining sharply in participation in recent years. Important features of the network, particularly its _\"firework\"_ structures, are noted and discussed, leading to a working hypothesis: that the firework clusters represent prolific authors whose emails do not generate much list discussion, and that these threads that are not useful for the PERCEIVE project's study of emerging threats, as they represent content like security advisories. Manual inspection of nodes confirms this hypothesis. \n",
    "\n",
    "In order to concentrate on actual discussion topics within the list, programmatic methods are developed to filter out these undesired firework structures. Once filtered, the network is amenable to  _community detection_, which in turn points to the need for further filtering. This general process -- filtering the network, identifying subcommunities, filtering again, and identifying subcommunites again -- emerges as a useful iterative procedure to find genuine discussion communities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Introduction\n",
    "\n",
    "The [PERCEIVE](https://sailuh.github.io/perceive/) project seeks to proactively identify upcoming cybersecurity threats through textual similarity. Social network analysis can be used to partition a network and evaluate its textual content, and hence provide word-selection criteria for defining corpus documents. \n",
    "\n",
    "The subject of this notebook, the [Full Disclosure (FD) mailing list](http://seclists.org/fulldisclosure/) is a \"public, vendor-neutral forum for detailed discussion of vulnerabilities and exploitation techniques, as well as tools, papers, news, and events of interest to the community.\"\n",
    "\n",
    "## 2.1 Problem Statement\n",
    "\n",
    "Although cybersecurity email mailing lists provide a rich source to identify emerging concepts, they contain a large amount of content that is irrelevant to the project's purpose, including but not limited to:\n",
    "\n",
    " * conference invitations[[1](http://seclists.org/fulldisclosure/2017/Feb/6)]\n",
    " * vendor announcements[[2](http://seclists.org/fulldisclosure/2016/Dec/48)]\n",
    " * extensive conversations on security topics[[3](http://seclists.org/fulldisclosure/2004/Jul/1026)]\n",
    " * a significant amount of trolling[[4](http://seclists.org/fulldisclosure/2008/Apr/96)] \n",
    " * and nonsense[[5](http://seclists.org/fulldisclosure/2009/Jul/289)] [[6](http://seclists.org/fulldisclosure/2004/Jul/796)].\n",
    "\n",
    "As some of this irrelevant content can be strictly tied to its producer, i.e., the **authors** of the **e-mail replies**, social network analysis provides an interesting opportunity for the isolation of relevant discussion topics in order to **filter** non-related vulnerability content. \n",
    "\n",
    "## 2.2 Network Definition\n",
    "\n",
    "Earlier in this project, the FD email lists were developed into networks of edges and nodes, divided by year. These original csv files are available [online](https://mega.nz/#F!CUEByR5I!GY56GzTpYz68IlTqj4aQNQ!fR8jFLxL). \n",
    "\n",
    "In the FD graphs, nodes represent either documents (i.e., emails) or authors, as identified by a nodeType attribute. Edges are directed, representing authorship and replies; edge weight indicates an increasing number of replies. \n",
    "\n",
    "The following screenshots show sample data from the edge and node lists for 2008. The edge lists provide three attributes: **source** (an author who posted an email), **target** (the document written), and **weight** (the number of times the author wrote back to the resulting thread). The node list attributes include an **id** (the author or the email document), a **label** (email address of an author or email subject for a document), **Label1** (response dates if applicable), **Label2** (URLs for the the documents), hexadecimal **Color** of red (#FF00000) or black (#000000) based on **nodeType** of author or document.\n",
    "\n",
    "2008 edge list sample | 2008 node list sample |\n",
    ":-------------------------:|:-------------------------:|\n",
    "[![](img/edges2008sample.png?raw=true)](img/edges2008sample.png?raw=true) | [![](img/nodes2008sample.png?raw=true)](img/nodes2008sample.png?raw=true)\n",
    "\n",
    "\n",
    "\n",
    "## 2.3 Tools used\n",
    "\n",
    "### 2.3.1 Gephi \n",
    "\n",
    "While [Gephi](http://gephi.org/) proved useful for data exploration, some difficulties arose. In particular, many of the core functions[[7](https://github.com/jaroslav-kuchar/Social-Network-Analysis/issues/2)] and plugins[[8](https://github.com/gephi/gephi/issues/1481)] once used for social network analysis are not compatible with current (0.9) software versions. Gephi specifications note that the 0.9.0 version (December 2015) \"Removed [the] Clustering module\"[[9](https://github.com/gephi/gephi/releases/tag/v0.9.0)] that these plugins relied upon.\n",
    "\n",
    "### 2.3.2 Python-igraph \n",
    "\n",
    "[Python-igraph](http://igraph.org/python/) (igraph hereafter) allows for programmatic manipulation of network data. Igraph can generate images via a `plot` function, but this is a slow process for large graphs. Igraph has a wide variety of import and export options for network data, including straightforward export of subgraphs.\n",
    "\n",
    "### 2.3.3 Interoperability of Gephi and igraph\n",
    "\n",
    "While Gephi can export graphs, its export implementations include temporary node properties like position and color attributes. Igraph can import Gephi-exported [GraphML](http://graphml.graphdrawing.org/) files (and those are available [here](https://mega.nz/#F!Dpdh2TjD!4Rd462mFXbdFn5Scs1WwUA). However, it was more useful in the long run to generate graphs in igraph directly from the provided edge and node lists. Igraph's exported GraphML files functioned as expected in Gephi.\n",
    "\n",
    "## 2.4 Generating graphs from edge and node lists\n",
    "\n",
    "In **Gephi**, graphs were generated via the `\"import spreadsheet\"` function, and separate Gephi projects saved for each year. Exported versions of these graphs are available in the [supplementary zip file](https://mega.nz/#!egFlzQ4A!Wf_V4UnyfoCNCE_ltT9F4veR-B8ep2uSmsOB-Z-K9tA).\n",
    "\n",
    "In **igraph**, graphs are generated via importing csv data into lists, then using igraph's `DictReader` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH D-W- 9793 12073 -- 2008 Full Disclosure network\n",
      "+ attr: name (g), color (v), id (v), label (v), label1 (v), label2 (v), nodetype (v), source (e), target (e), weight (e)\n"
     ]
    }
   ],
   "source": [
    "from igraph import Graph, summary\n",
    "from csv import DictReader\n",
    "\n",
    "# 2008 will be the sample year for this introductory analysis, but let's define it as a variable\n",
    "# for future development of functions that will work for all years\n",
    "year = '2008'  \n",
    "\n",
    "# import edge list and vertex list as lists of dictionaries:\n",
    "e = []\n",
    "with open('data/input/author_threadID_edgelist_' + year + '.csv') as csvfile:\n",
    "    reader = DictReader(csvfile, dialect='excel')\n",
    "    reader.fieldnames = [name.lower() for name in reader.fieldnames]  # igraph expects lowercase attribute names\n",
    "    for row in reader:\n",
    "        row['weight'] = int(row['weight'])  # convert weight from string to int\n",
    "        e.append(row)\n",
    "v = []\n",
    "with open('data/input/nodelist_aut_doc_' + year +'.csv') as csvfile:\n",
    "    reader = DictReader(csvfile, dialect='excel')\n",
    "    reader.fieldnames = [name.lower() for name in reader.fieldnames]  # igraph expects lowercase attribute names\n",
    "    for row in reader:\n",
    "        v.append(row)\n",
    "\n",
    "# build a graph from the lists; see http://igraph.org/python/doc/igraph.Graph-class.html#DictList\n",
    "ml = Graph.DictList(vertices=v, edges=e, directed=True, vertex_name_attr='id')  # specify the 'id' attribute here\n",
    "                                                                                # because igraph anticipates a 'name' instead\n",
    "\n",
    "ml['name'] = year + ' Full Disclosure network'  # provide a name for this graph\n",
    "\n",
    "summary(ml)  # list properties and attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary command providing the output seen above is explained in the igraph documentation[[10](http://igraph.org/python/doc/igraph.summary'.GraphSummary-class.html)]. In this example, the four-character code \"D-W-\" indicates that the graph is directed and weighted. The graph for 2008 has 9793 vertices (nodes) and 12073 edges. \n",
    "\n",
    "The list of attributes in the summary (\"name\", \"color\", etc.) are those for the graph (g), vertices (v), or edges (e). \n",
    "\n",
    "In the remainder of this notebook, **2008** will be used for single-year analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Preliminary overview\n",
    "## 3.1 Visual assessment via Gephi-generated images\n",
    "\n",
    "Importing the entire graphs for each year into Gephi allowed for early visual inspection and exploration of the FD lists.  \n",
    "\n",
    "The following table includes full-network Gephi graphics for each year of the email list's existence; blue nodes represent authors and red nodes represent documents. Click through for full-size renderings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " |||\n",
    ":-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|\n",
    "[![](img/network_over_time/fd2002.png?raw=true)](img/network_over_time/fd2002.png?raw=true)  |  [![](img/network_over_time/fd2003.png?raw=true)](img/network_over_time/fd2003.png?raw=true) |  [![](img/network_over_time/fd2004.png?raw=true)](img/network_over_time/fd2004.png?raw=true) |  [![](img/network_over_time/fd2005.png?raw=true)](img/network_over_time/fd2005.png?raw=true)\n",
    "[![](img/network_over_time/fd2006.png?raw=true)](img/network_over_time/fd2006.png?raw=true)  |  [![](img/network_over_time/fd2007.png?raw=true)](img/network_over_time/fd2007.png?raw=true) |  [![](img/network_over_time/fd2008.png?raw=true)](img/network_over_time/fd2008.png?raw=true) |  [![](img/network_over_time/fd2009.png?raw=true)](img/network_over_time/fd2009.png?raw=true)\n",
    "[![](img/network_over_time/fd2010.png?raw=true)](img/network_over_time/fd2010.png?raw=true)  |  [![](img/network_over_time/fd2011.png?raw=true)](img/network_over_time/fd2011.png?raw=true) |  [![](img/network_over_time/fd2012.png?raw=true)](img/network_over_time/fd2012.png?raw=true) |  [![](img/network_over_time/fd2013.png?raw=true)](img/network_over_time/fd2013.png?raw=true) \n",
    "[![](img/network_over_time/fd2014.png?raw=true)](img/network_over_time/fd2014.png?raw=true)  |  [![](img/network_over_time/fd2015.png?raw=true)](img/network_over_time/fd2015.png?raw=true) |  [![](img/network_over_time/fd2016.png?raw=true)](img/network_over_time/fd2016.png?raw=true)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 The expansion and contraction of Full Disclosure\n",
    "\n",
    "It is clear from a quick look at the graphs that the overall pattern of the Full Disclosure network has shifted over time. In the early years of the list, there were tightly clustered conversations, particularly from about 2003-2006. As the years went by, the level of discussion seems to have dropped. Some of this pattern can be inferred simply from the file sizes of the edge and node lists, or by counting the nodes.\n",
    "\n",
    "The visual impression is further confirmed by a documented change in the FD network in March, 2014, when one of the original managers of the list decided to halt the list entirely[[11](http://seclists.org/fulldisclosure/2014/Mar/332)] but another team soon revived it[[12](http://seclists.org/fulldisclosure/2014/Mar/333)]. \n",
    "\n",
    "Following the 2014 format change, the number of edges drops significantly, and the list displays a different network structure from the earlier years. Currently, the list remains active but few members respond to published posts.\n",
    "\n",
    "## 3.3 \"Firework\" patterns\n",
    "\n",
    "Visual analysis of the graphs for each year showed distinct fireworks patterns throughout the lifecycle of the list. These are cases where one author is posting to the list many times, with little or no response from other people on the list, resulting in a hub-and-spoke graph form. The working hypothesis is that these firework patterns generally represent security advisories. If so, these are discussions known issues, and not useful for the project's overall predictive goals.\n",
    "\n",
    "These fireworks were analyzed both visually, in Gephi, and programmatically, in igraph, to test the hypothesis. \n",
    "\n",
    "In **Gephi**, manual examination included use of the [Linkfluence plugin](https://marketplace.gephi.org/plugin/linkfluence-plugin/) to launch URLs in a web browser directly from nodes studied. This node-by-node analysis demonstrated that firework nodes were security advisories[[13](http://seclists.org/fulldisclosure/2007/Sep/310)][[14](http://seclists.org/fulldisclosure/2007/Apr/291)][[15](http://seclists.org/fulldisclosure/2007/Aug/8)].\n",
    "\n",
    "In **igraph**, it was informative to assess each author node and examine the in-degree of its connected (document) nodes. In cases where all (or most) of an author's neighbors have an in-degree of one, the author is the hub of a firework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of authors and their connected (document) vertices, among first 45 in total list,\n",
      "limited to those with neighbors with max in-degree < 2\n",
      "\n",
      "-------------------------------------------------------\n",
      "andur matrix <andurmatrix () gmail com> \n",
      "\n",
      "  In-degree\t Label\n",
      "  ---------\t -----\n",
      "  1 \t\t Re: [OOT] Thesis for master degree\n",
      "  MAX: 1\n",
      "  AVERAGE: 1.0\n",
      "\n",
      "-------------------------------------------------------\n",
      "Matousec - Transparent security Research <research () matousec com> \n",
      "\n",
      "  In-degree\t Label\n",
      "  ---------\t -----\n",
      "  1 \t\t Kerio Fake 'iphlpapi' DLL injection Vulnerability\n",
      "  1 \t\t Outpost Bypassing Self-Protection using file\tlinks Vulnerabi\n",
      "  1 \t\t Comodo Multiple insufficient argument validation of hooked S\n",
      "  1 \t\t Comodo DLL injection via weak hash function\texploitation Vul\n",
      "  1 \t\t Comodo Bypassing settings protection using magic\tpipe Vulner\n",
      "  1 \t\t Norton Insufficient validation of 'SymTDI' driver\tinput buff\n",
      "  1 \t\t Norton Multiple insufficient argument validation of hooked S\n",
      "  1 \t\t ZoneAlarm Multiple insufficient argument validation of hooke\n",
      "  1 \t\t ZoneAlarm Insufficient validation of 'vsdatant' driver input\n",
      "  1 \t\t Bypassing PFW/HIPS open process control with\tuncommon identi\n",
      "  1 \t\t Outpost Enforcing system reboot with\t'outpost_ipc_hdr' mutex\n",
      "  1 \t\t Kaspersky Multiple insufficient argument validation of hooke\n",
      "  1 \t\t Plague in (security) software drivers & BSDOhook\tutility\n",
      "  MAX: 1\n",
      "  AVERAGE: 1.0\n",
      "\n",
      "-------------------------------------------------------\n",
      "Sebastian Wolfgarten <sebastian.wolfgarten () gmx net> \n",
      "\n",
      "  In-degree\t Label\n",
      "  ---------\t -----\n",
      "  1 \t\t Security contact at TrendMicro\n",
      "  1 \t\t Buffer overflow in VSAPI library of Trend Micro\tVirusWall 3.\n",
      "  MAX: 1\n",
      "  AVERAGE: 1.0\n",
      "\n",
      "-------------------------------------------------------\n",
      "xploitzz <xploitzz () gmail com> \n",
      "\n",
      "  In-degree\t Label\n",
      "  ---------\t -----\n",
      "  1 \t\t Vista Reduced Function mode\ttriggered&In-Reply-To=AA4FD01470\n",
      "  MAX: 1\n",
      "  AVERAGE: 1.0\n",
      "\n",
      "-------------------------------------------------------\n",
      "Tal Argoni <moskito () 012 net il> \n",
      "\n",
      "  In-degree\t Label\n",
      "  ---------\t -----\n",
      "  1 \t\t Inforamtion Discloser Vulnerabilities in\t\"phpMyAdmin\"\n",
      "  MAX: 1\n",
      "  AVERAGE: 1.0\n",
      "\n",
      "-------------------------------------------------------\n",
      "<sftsi () hushmail com> \n",
      "\n",
      "  In-degree\t Label\n",
      "  ---------\t -----\n",
      "  1 \t\t It's all in the details, sapheal\n",
      "  MAX: 1\n",
      "  AVERAGE: 1.0\n",
      "\n",
      "-------------------------------------------------------\n",
      "Vic Vandal <vvandal () well com> \n",
      "\n",
      "  In-degree\t Label\n",
      "  ---------\t -----\n",
      "  1 \t\t CarolinaCon 2007 - Call for Speakers/Papers\n",
      "  1 \t\t Re: Call For Participants For A Research Study Of\tHacker Cul\n",
      "  1 \t\t CarolinaCon-2008, March 28th-30th\n",
      "  1 \t\t CarolinaCon 2007 Announcement/Press Release\n",
      "  1 \t\t CarolinaCon-2008, March 28th-30th,\tfull agenda posted\n",
      "  1 \t\t CarolinaCon presentation drafts\n",
      "  1 \t\t CarolinaCon 2008 - Call For Papers/Speakers\n",
      "  MAX: 1\n",
      "  AVERAGE: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('List of authors and their connected (document) vertices, among first 45 in total list,\\nlimited to those with neighbors with max in-degree < 2')\n",
    "for node in ml.vs(nodetype_eq='author')[0:45]:\n",
    "    indegrees = [ml.degree(_, mode='in') for _ in ml.neighbors(node)]\n",
    "    if indegrees:  # a few authors have 0 neighbors... \n",
    "        if max(indegrees) < 2:\n",
    "            print()\n",
    "            print('-' * 55)\n",
    "            print(node['label'], '\\n')\n",
    "            print('  In-degree\\t Label')\n",
    "            print('  ---------\\t -----')\n",
    "            for _ in ml.neighbors(node):\n",
    "                print(' ', ml.degree(_, mode='in'), '\\t\\t', ml.vs[_]['label'][0:60] )\n",
    "            print('  MAX:', max(indegrees))\n",
    "            print('  AVERAGE:', sum(indegrees) / max(len(indegrees), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code example, it is revealed that authors \"Matousec\" and \"Vic Vandal\" are centers of fireworks. Email subjects suggest that these are security advisories and conference announcements, respectively. \n",
    "\n",
    "A few authors in the 2008 network have zero neighboring nodes. These are responses to email threads from earlier years. In general, we are not interested in these delayed responses. Security literature[[16](https://pdfs.semanticscholar.org/6431/5b4290353cf7e46d9cfa6cba566479ff275e.pdf)] suggests that vulnerabilities are only of interest in the short term, and **discussions within a single year** are a reasonable target for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Filtering the network\n",
    "\n",
    "Igraph allows for removal of vertices from the graph based on useful criteria. Since the \"fireworks\" are not desired in future analysis, they can be removed.\n",
    "\n",
    "## 4.1 Saving some attributes before filtering\n",
    "\n",
    "Before filtering, it may be useful to store some graph statistics in the node attributes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr = ml.pagerank(directed=True, weights='weight')\n",
    "for idx, _ in enumerate(ml.vs):\n",
    "    _['original_pagerank'] = pr[idx]\n",
    "    _['original_enumeration'] = idx - 1  # this can link us back to the node list if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A simple function to list total numbers of nodes and authors will be useful as we attempt to shrink the analyzed graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vertices for 2008 Full Disclosure network :\n",
      "     9793 including 2438 authors\n"
     ]
    }
   ],
   "source": [
    "def nodeCount(g):\n",
    "    print('Total vertices for', g['name'], ':\\n    ', len(g.vs), 'including', len(g.vs(nodetype_eq='author')), 'authors')\n",
    "\n",
    "nodeCount(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Removing fireworks\n",
    "The earlier analysis of the in-degree of authors' neighbors suggested that those authors whose neighbors' in-degree was mostly 1 are centers of fireworks. A fuller examination of the data revealed that these types of list postings occasionally gain responses[[16](http://seclists.org/fulldisclosure/2008/Feb/440)]. Therefore, it was determined that a firework including documents with _average_ (or mean) in-degrees of < 1.2 can be removed from the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out authors with neighbors mostly of in-degree 1...\n",
      "Total vertices for 2008 Full Disclosure network (fireworks removed) :\n",
      "     9253 including 1898 authors\n"
     ]
    }
   ],
   "source": [
    "# now let's start filtering...\n",
    "# first remove authors with neighbors mostly of in-degree 1\n",
    "print('Filtering out authors with neighbors mostly of in-degree 1...')\n",
    "\n",
    "for node in ml.vs:\n",
    "    if node['nodetype'] == 'author':\n",
    "        indegrees = [ml.degree(_, mode='in') for _ in ml.neighbors(node)]\n",
    "        if indegrees:  # a few authors have 0 neighbors... this is something to investigate later\n",
    "            if sum(indegrees) / max(len(indegrees), 1) < 1.2: #  there are examples where most of the indegrees are 1 but\n",
    "                                                     #  we have a random response, so let's use the mean\n",
    "                ml.delete_vertices(node) #  deleting vertices also deletes all of its edges\n",
    "ml['name'] = ml['name'] + ' (fireworks removed)'\n",
    "\n",
    "nodeCount(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above reduction in network size is helpful, but the removal of firework hubs is likely to leave a number of isolated documents in the graph. Removing all nodes with degree 0 can complete the _firework cleanup_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out documents or authors with degree 0...\n",
      "Total vertices for 2008 Full Disclosure network (fireworks removed) (isolated nodes removed) :\n",
      "     7179 including 1898 authors\n"
     ]
    }
   ],
   "source": [
    "print('Filtering out documents or authors with degree 0...')\n",
    "for node in ml.vs:\n",
    "    if ml.degree(node) == 0: \n",
    "        ml.delete_vertices(node)\n",
    "ml['name'] = ml['name'] + ' (isolated nodes removed)'\n",
    "nodeCount(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers after firework-filtering are still large. In order to focus more narrowly on relevant portions of this network, some deeper social network analysis techniques are required.\n",
    "\n",
    "# 5 Social network analysis\n",
    "\n",
    "The network structure varies considerably across the years. This provides an opportunity to partition a network for a given year into several clusters and investigate if the visualized structure has any association to the textual content of a given **e-mail thread** discussion.\n",
    "\n",
    "If such association exists, then we can leverage the **social network structure** in order to simplify the identification of emerging concepts through text alone. For instance, identifying a group of individuals who prefer certain subjects, or are spammers or trolls, may become a trivial pre-processing stage before textual content is analyzed for _emerging_ concepts.\n",
    "\n",
    "We begin by considering 2 methods to more precisely define how to partition a network at any given year: \n",
    "\n",
    " * Community Detection \n",
    " * Betweenness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Community Detection\n",
    "\n",
    "In real-world social networks, there is a tendency towards clustering of nodes with strong ties: if I have a close friend who has another close friend, I am likely to make a connection with that person. There are mathematical methods for identifying clusters based on the existing edges of their neighbors in comparison to the possible connections among them.\n",
    "\n",
    "Both Gephi and igraph have clustering functions, but igraph’s are more robust and allow us to easily filter out subgraphs.\n",
    "\n",
    "Igraph's community measures do not support directed graphs, as seen in the warning message below, but the directionality can be removed. It is worth noting that directionality is implied in the structure of the graph (authors write or respond to documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\igraph\\__init__.py:1072: RuntimeWarning: This method was developed for undirected graphs at src\\community.c:1565\n",
      "  membership, _, q = GraphBase.community_leading_eigenvector(self, clusters, **kwds)\n"
     ]
    }
   ],
   "source": [
    "com = ml.community_leading_eigenvector(weights='weight', clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering attempt, leading eigenvector:\n",
      "Clustering with 7179 elements and 1092 clusters\n"
     ]
    }
   ],
   "source": [
    "ml.to_undirected(combine_edges='max') # eliminate the directionality\n",
    "\n",
    "# Attempt to identify communities\n",
    "\n",
    "com = ml.community_leading_eigenvector(weights='weight', clusters=3)\n",
    "print('clustering attempt, leading eigenvector:')\n",
    "summary(com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igraph allows a suggested number of communities generated, but on the entire network, the applied settings fail (the program cannot divide the network into 3 clusters, in this case).\n",
    "\n",
    "It will be useful to define a method of saving cluster information in vertex attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def saveClusterInfo(g, com, attr):\n",
    "    '''add to graph 'g' a cluster number from community 'com' as 'attr' attribute'''\n",
    "    for idx, c in enumerate(com):\n",
    "        for _ in c:\n",
    "            g.vs[_][attr] = idx\n",
    "\n",
    "# Apply above function to our overall graph\n",
    "saveClusterInfo(ml, com, 'filtered_clustering')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Centrality measures\n",
    "\n",
    "Igraph allows us to calculate _betweenness centrality_ and _pagerank_. These are related measures for identifying the most central vertices in a graph.\n",
    "\n",
    "We can add a function to calculate and store these measures as attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add betweenness centrality, pagerank, and clustering info to original graph\n",
    "def saveCentrality(g, name):\n",
    "    bc = g.betweenness()\n",
    "    for idx, node in enumerate(g.vs):\n",
    "        g.vs[idx][name + '_betweenness'] = bc[idx]\n",
    "\n",
    "    pr = g.pagerank(directed=False)\n",
    "    for idx, node in enumerate(g.vs):\n",
    "        g.vs[idx][name + '_pagerank'] = pr[idx]\n",
    "    return bc, pr\n",
    "\n",
    "bc, pr = saveCentrality(ml, 'filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Community and centrality analysis\n",
    "\n",
    "Examining the results in igraph can reveal some useful information. Beginning with the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092 clusters.\n",
      "maximum size: 5594\n",
      "minimum size: 1\n",
      "\n",
      "Summary of first 10 clusters:\n",
      "[0] has size of 5594. Vertices: [0, 1, 2, 3, 4] (and 5589 more)\n",
      "[1] has size of 8. Vertices: [37, 1922, 1970, 2242, 2730] (and 3 more)\n",
      "[2] has size of 4. Vertices: [44, 1931, 2847, 6026] \n",
      "[3] has size of 2. Vertices: [80, 1973] \n",
      "[4] has size of 4. Vertices: [81, 83, 1974, 4715] \n",
      "[5] has size of 2. Vertices: [101, 1997] \n",
      "[6] has size of 3. Vertices: [107, 2009, 2686] \n",
      "[7] has size of 5. Vertices: [118, 136, 2017, 2020, 2021] \n",
      "[8] has size of 5. Vertices: [130, 2033, 2186, 2649, 3428] \n",
      "[9] has size of 4. Vertices: [133, 2036, 2037, 2094] \n"
     ]
    }
   ],
   "source": [
    "# First, we will define a function to summarize the clustering attempt.\n",
    "def summarizeClusters(com, n=5):\n",
    "    print(len(com), 'clusters.')\n",
    "    print('maximum size:', len(max(com, key=len)))\n",
    "    print('minimum size:', len(min(com, key=len)))\n",
    "\n",
    "    print('\\nSummary of first', n, 'clusters:')\n",
    "    for i in range(n):\n",
    "        etc = ''\n",
    "        if len(com[i]) > 5:\n",
    "            etc += '(and ' + str(len(com[i]) - 5) + ' more)'\n",
    "        print('[{}] has size of {}. Vertices: {} {}'.format(i, len(com[i]), com[i][0:5], etc))\n",
    "\n",
    "summarizeClusters(com, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output immediately demonstrates that one cluster is by far the largest in the network -- consisting here of 5594 nodes (out of 7179 in the total network). Most of the other clusters are tiny in comparison.\n",
    "\n",
    "The initial impressions from betweenness measures are also interesting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 : 100%\n",
      "Node 1 : 62%\n",
      "Node 2 : 50%\n",
      "Node 3 : 48%\n",
      "Node 4 : 48%\n",
      "Node 5 : 48%\n",
      "Node 6 : 29%\n",
      "Node 7 : 27%\n",
      "Node 8 : 19%\n",
      "Node 9 : 18%\n",
      "Node 10 : 17%\n",
      "Node 11 : 16%\n",
      "Node 12 : 15%\n",
      "Node 13 : 15%\n",
      "Node 14 : 14%\n"
     ]
    }
   ],
   "source": [
    "# sort the betweenness and then list nodes in order of centrality\n",
    "bc.sort(reverse=True)\n",
    "max_bc = max(bc)\n",
    "bc_normalized = [x / max_bc for x in bc]\n",
    "\n",
    "for idx,val in enumerate(bc_normalized[0:15]):\n",
    "    print('Node', idx, ':', '{:.0%}'.format(bc_normalized[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the betweenness centrality quickly drops, which may indicate nodes that often discuss different subjects for contributing e-mail discussions for different \"community of threats\".\n",
    "\n",
    "At this point it is helpful to look at some visualizations to assess the 2008 graph in its current state.\n",
    "\n",
    "### 5.2.2 Visualizing the current graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export the ml graph\n",
    "filename = 'data/output/out_' + year + '_filtered.graphml'\n",
    "ml.save(filename, format='graphml') # export graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the resulting graph is opened in Gephi, and colored by cluster, it is apparent that one large \"blob\" still comprises the bulk of the network. \n",
    "\n",
    "![Filtered graph](img/2008_clusters_betweenness.png?raw=true \"Filtered graph\")\n",
    "\n",
    "There are still too many communities for easy analysis. The next objective is to isolate the central blob.\n",
    "\n",
    "## 5.3 Breaking down the network into subgraphs\n",
    "\n",
    "### 5.3.1 The blob\n",
    "In the case of year 2008, the blob is easily identifiable, taking up majority of the graph. In other years -- particularly later years -- this will not be the case. More sophisticated selection criteria will have to be developed based on the initial clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U-W- 5594 8576 -- 2008 subgraph for cluster 0 (blob)\n",
      "+ attr: name (g), color (v), filtered_betweenness (v), filtered_clustering (v), filtered_pagerank (v), id (v), label (v), label1 (v), label2 (v), nodetype (v), original_enumeration (v), original_pagerank (v), source (e), target (e), weight (e)\n"
     ]
    }
   ],
   "source": [
    "# The blob has been manually identified as cluster 0\n",
    "\n",
    "blob = ml.induced_subgraph(com[0])\n",
    "blob['name'] = year + ' subgraph for cluster 0 (blob)'\n",
    "summary(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering attempt, leading eigenvector:\n",
      "Clustering with 5594 elements and 8 clusters\n"
     ]
    }
   ],
   "source": [
    "# Now working with the blob, we can re-attempt clustering and bc!\n",
    "\n",
    "com = blob.community_leading_eigenvector(weights='weight', clusters=8)\n",
    "print('clustering attempt, leading eigenvector:')\n",
    "summary(com)\n",
    "saveClusterInfo(blob, com, 'blob_clustering')\n",
    "\n",
    "bc, pr = saveCentrality(blob, 'blob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igraph's clustering algorithms are far more effective on the blob than they were on the whole graph. Here, we can specify the number of clusters we are seeking. Experimenting with results, though, demonstrated that there was little significant difference among different numbers of communities; in each case the next steps are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5.3.2 The \"blob\" colored by subcommunity\n",
    "[8-cluster visualization](https://github.com/jeffgerhard/perceive_personal/blob/master/images/blob8clusters.png?raw=true) | [15-cluster visualization](https://github.com/jeffgerhard/perceive_personal/blob/master/images/blob15clusters.png?raw=true) |\n",
    ":-------------------------:|:-------------------------:|\n",
    "[![](img/blob8clusters.png?raw=true)]img/blob8clusters.png?raw=true) | [![](img/blob15clusters.png?raw=true)](img/blob15clusters.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blob displays distinctive subcommunities. A few of these new clusters _still_ include fireworks (green in these visualizations), but others (colored purple here) are strongly suggestive of discussion communities in which multiple authors interact with each others' messages. \n",
    "\n",
    "Examining these subcommunities in turn provides an opportunity to discover real communities and begin to develop a **corpus** from the Full Disclosure discussion.\n",
    "\n",
    "## 5.4 Saving the blob subcommunities\n",
    "\n",
    "Using 8 clusters as a baseline for analysis, the relevant subgraphs can include all useful attributes and be exported in turn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's try each cluster separately\n",
    "\n",
    "subs = {}  # build all the clusters into a dictionary\n",
    "for idx, c in enumerate(com):\n",
    "    subs[idx] = blob.induced_subgraph(com[idx])\n",
    "    subs[idx]['name'] = year + ' blob subgraph ' + str(idx) + ' of ' + str(len(com))\n",
    "    # rerun the centrality, clustering, pagerank analyses\n",
    "    subcom = subs[idx].community_leading_eigenvector(weights='weight', clusters=5)\n",
    "    saveClusterInfo(subs[idx], subcom, 'local_clustering')\n",
    "    bc, pr = saveCentrality(subs[idx], 'local')    \n",
    "    filename = 'output/' + subs[idx]['name'].replace(' ', '_') + '_out.graphml'\n",
    "    # subs[idx].save(filename, format='graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line above, commented out here, will generate subgraph GraphML file for each subcommunity. Output files from the above code snippet are available in the [supplementary zip](https://mega.nz/#!egFlzQ4A!Wf_V4UnyfoCNCE_ltT9F4veR-B8ep2uSmsOB-Z-K9tA) and were used to generate the images below.\n",
    "\n",
    "\n",
    "Loading each subcommunity into Gephi, and retaining the original coloring (red nodes for authors, black for documents), the different graph structures for each subcommunity become clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5.4.1 Each subcommunity of the 2008 blob\n",
    "[Sub-cluster 0](img/blob_subgraphs/subgraph0.png?raw=true) | [Sub-cluster 1](img/blob_subgraphs/subgraph1.png?raw=true) | [Sub-cluster 2](img/blob_subgraphs/subgraph2.png?raw=true) | [Sub-cluster 3](img/blob_subgraphs/subgraph3.png?raw=true) |\n",
    ":-------------------------:|:-------------------------:|:-------------------------:|:-------------------------:|\n",
    "[![](img/blob_subgraphs/subgraph0.png?raw=true)](img/blob_subgraphs/subgraph0.png?raw=true) | [![](img/blob_subgraphs/subgraph1.png?raw=true)](img/blob_subgraphs/subgraph1.png?raw=true) | [![](img/blob_subgraphs/subgraph2.png?raw=true)](img/blob_subgraphs/subgraph2.png?raw=true) | [![](img/blob_subgraphs/subgraph3.png?raw=true)](img/blob_subgraphs/subgraph3.png?raw=true)\n",
    "[**Sub-cluster 4**](img/blob_subgraphs/subgraph4.png?raw=true) | [**Sub-cluster 5**](img/blob_subgraphs/subgraph5.png?raw=true) | [**Sub-cluster 6**](img/blob_subgraphs/subgraph6.png?raw=true) | [**Sub-cluster 7**](img/blob_subgraphs/subgraph7.png?raw=true)\n",
    "[![](img/blob_subgraphs/subgraph4.png?raw=true)](img/blob_subgraphs/subgraph4.png?raw=true) | [![](img/blob_subgraphs/subgraph5.png?raw=true)](img/blob_subgraphs/subgraph5.png?raw=true) | [![](img/blob_subgraphs/subgraph6.png?raw=true)](img/blob_subgraphs/subgraph6.png?raw=true) | [![](img/blob_subgraphs/subgraph7.png?raw=true)](img/blob_subgraphs/subgraph7.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-groups 2 and 6 are too small for analysis, but the remaining groups represent real communities in dialogue. Thus, the sub-clusters represent opportunities to identify individual authors and attempt to identify conversational topics. Two problems remain to discuss:\n",
    "\n",
    "- Do these groupings have distinctive characteristics? \n",
    "- How can we assess the remaining firework features (e.g. in subcluster 7 above)? Is it reasonable to generalize the original filtering process at the subgraph level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Cluster features and manual textual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- **Cluster 0** (161 nodes, 183 edges) features a number of discussions of _exploit auctions or sales_[[17](http://seclists.org/fulldisclosure/2007/Jul/93)], [[18](http://seclists.org/fulldisclosure/2007/Jul/116)], [[19](http://seclists.org/fulldisclosure/2007/Nov/226) and includes a  potential firework clustering around user `Nick FitzGerald <nick () virus-l demon co uk>`. A researcher more familiar with security matters should assess whether or not the Nick FitzGerald messages (for example [[20](http://seclists.org/fulldisclosure/2007/Jan/443)], [[21](http://seclists.org/fulldisclosure/2008/Jan/422)], [[22](http://seclists.org/fulldisclosure/2008/Dec/368)]) are valuable for further study; they are primarily general discussions of security topics, in conversation with a wider group of list members. **Potential keywords**: _exploits, sales, auction, zero-day_\n",
    "- **Cluster 1** (488 nodes, 983 edges) is heavily dominated by three authors, `Ureleet <ureleet () gmail com>`, `Valdis.Kletnieks () vt edu`, and above all `n3td3v <xploitable () gmail com>`, an infamous list member discussed in several forums even outside of Full Disclosure[[23](http://it.toolbox.com/blogs/managing-infosec/security-trolls-n3td3v-12460)], [[24](http://hackerfactor.com/papers/who_is_n3td3v.pdf)]. n3td3v responds to a wide range of topics including over 300 separate emails in the overall 2008 graph. The fact that these users are not typical makes analysis difficult. The best practice is to treat them as trolls (n3td3v is referred to as a troll in the cited links, with some caveats.) Conveniently, the blob clustering has linked together all of these trolling-related postings into one giant subgraph of argumentation and flame wars. (Examples of such posts include [[25](http://seclists.org/fulldisclosure/2008/Dec/200)], [[26](http://seclists.org/fulldisclosure/2008/Jun/104)], [[27](http://seclists.org/fulldisclosure/2008/Oct/65)].) This cluster can be dropped from further discussion. **Potential keywords**: _n3td3v_\n",
    "- **Cluster 2**, as mentioned earlier, can also be ignored for its small size of 26 nodes.\n",
    "- **Cluster 3** is the largest in the blob (4151 nodes, 4039 edges) and corresponds to the large purple communities in the blob overviews above. This cluster is so large that it is a **candidate for further subdivision**, treating it as yet another 'blob.' It also includes _fireworks_ within its graph. Fireworks within this cluster includ, for example, author ` zdi-disclosures () 3com com` whose postings are in fact security advisories (e.g. [[28](http://seclists.org/fulldisclosure/2008/Apr/83)]. These authors' advisories garnered some responses in the original full-year network and might have been removed with more robust filtering in an earlier stage. For non-firework postings, a manual overview suggests a wide variety of topics in this cluster, including many that touch on the mailing list's central topic, [full-disclosure](https://en.wikipedia.org/wiki/Full_disclosure_%28computer_security%29) security postings[[29](http://seclists.org/fulldisclosure/2008/Jan/593)]. [[30](http://seclists.org/fulldisclosure/2008/Apr/554)], [[31](http://seclists.org/fulldisclosure/2007/Jul/147)].\n",
    "- **Cluster 4** is a small subgraph (118 nodes, 138 edges) notable for Windows-focused discussions[[31](http://seclists.org/fulldisclosure/2007/Apr/2), [[32](http://seclists.org/fulldisclosure/2008/Mar/58)], including then-current conversations about Windows Vista in comparison to Windows XP[[31](http://seclists.org/fulldisclosure/2008/Jan/558). There are some additional general discussion of security concerns, but little to make this small group distinct from the overall list. **Potential keywords**: _Microsoft, Windows_\n",
    "- **Cluster 5** is another small subgraph (145 nodes, 164 edges) with a few dominant authors, similar in some ways to cluster 1. These authors seem to treat the Full Disclosure list as a **social group** as well as a security forum, with email posts featuring titles like \"Came across this site\"[[32](http://seclists.org/fulldisclosure/2007/Sep/118)], \"Anyone have a Lindows/Linspire contact\"[[33](http://seclists.org/fulldisclosure/2007/Apr/558), and \"Southwest Airlines Ticket Silliness\"[[34](http://seclists.org/fulldisclosure/2008/Feb/0)]. Although the members of this clustering discuss some security measures, their emphasis on general discussions remove this group from consideration.\n",
    "- **Cluster 6** (21 nodes, 0 edges) is again too small to analyze.\n",
    "- **Cluster 7** (484 nodes, 601 edges) presents a problem for future analysis: the first examples of truly belligerent trolling. In cluster 1 above, n3td3v and other users were extremely active and annoyed others, but did not display overtly antisocial behavior. At least one member of cluster 7 posted offensive[[35](http://seclists.org/fulldisclosure/2008/Apr/22)][[36](http://seclists.org/fulldisclosure/2008/May/238)] content on a regular basis, while other users here display more aggression[[37](http://seclists.org/fulldisclosure/2008/Jan/504)] or attacks on personal lives[[38](http://seclists.org/fulldisclosure/2007/Feb/123)]. The difficulty in this cluster is assessing the level of discussion of actual security concerns vs. trolling and attacks. This subcluster is thus a strong candidate for **further clustering analysis** which is likely to separate out the authors who engage in malbehavior from the rest of the group.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6 Conclusions\n",
    "\n",
    "## 6.1 A general framework for social network analysis\n",
    "\n",
    "The techniques developed above can be summarized as follows:\n",
    "1. Filter out \"firework\" nodes (and the subsequently orphaned nodes that the firework authors originally posted).\n",
    "2. Identify subcommunities within the graph that deserve deeper analysis (e.g., the \"blob\")\n",
    "3. Subdivide into communities again.\n",
    "4. Manually analyze the resulting subgraphs.\n",
    "\n",
    "This strategy was successful, though incomplete. Two of the resulting subgraphs (numbers 3 and 7 above) merit _further_ subdivision. \n",
    "\n",
    "The results suggest that a more fully-developed programming framework could automate much of this work, as a researcher could discard clusters based on graph structure **or** content, narrowing in on relevant subclusters of subclusters. Early stages of such a framework in Python are suggested above.\n",
    "\n",
    "The preliminary results based on the subclusters of the initial \"blob\" are encouraging, demonstrating that social-focused clusters (like cluster 5) and flame-war clusters (like cluster 1) can be isolated from the surrounding graphs through community detection.\n",
    "\n",
    "\n",
    "## 6.2 Assessing tools used\n",
    "\n",
    "Gephi and igraph were adequate for this research, but both tools are flawed. Alternatives worthy of consideration for future iterations include:\n",
    "\n",
    "- [Cytoscape](http://www.cytoscape.org/) -- comparable to Gephi, but with the potentially useful feature of allowing for publication of graph data as an interactive web page[[38](https://github.com/miriamposner/cytoscape_tutorials/blob/master/publishing-your-network-diagram.md)].\n",
    "- [NetworkX](https://networkx.github.io/) -- comparable to igraph. The main reason to suggest NetworkX as a potential replacement for igraph is that NetworkX currently has a better-functioning integration with Jupyter notebooks, whereas igraph  faces bugs when attempting to plot images within a notebook[[40](https://github.com/igraph/python-igraph/issues/88).\n",
    "\n",
    "\n",
    "## 6.3 Suggestions for next steps\n",
    "\n",
    "- Next steps for this analysis should include building out the skeleton Python program above to adhere to \"Don't Repeat Yourself\" principles and allow for automatic analysis of **multiple years** of the Full Disclosure list, breaking down large networks into manageable subgraphs.\n",
    "- Rather than relying on static csv edge and node lists, it is possible to **pull graph data directly from a database** into igraph[[42](https://stackoverflow.com/questions/25396799/create-a-directed-weighted-graph-using-python-igraph-and-mysql-results/25412608#25412608)]. As the PERCEIVE project moves in this direction, the social network analysis segment will be able to keep up.\n",
    "- Igraph's community-generation algorithms allow a user to provide a desired number of subcommunities. A Jupyter notebook with **interactive features** could allow a user to modify this number and visually assess the results, potentially identifying a number that could most readily identify targeted subcommunities.\n",
    "- The research conclusions fail to develop a model of an **ideal subcommunity size** for analysis. Cluster 6 with 21 nodes was too small to have meaningful discussion, while Cluster 3 with 4151 nodes was too large to break down. A useful middle ground could be identified and then program parameters automatically adjusted to attempt to generate subgroups of preferred size.\n",
    "- Manual examination of dozens of nodes is prone to error. Future researchers should utilize **multiple human analysts** to identify and confirm commonalities among subcommunity members. This task could be facilitated by services like Mechanical Turk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
